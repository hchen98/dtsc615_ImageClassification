{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the env and lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "#!pip install seaborn\n",
    "#!pip install directory_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_core.paths import jupyter_data_dir\n",
    "print(jupyter_data_dir())\n",
    "\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the GPU/CPU info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "print(\"Here: \")\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print()\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"#############################################################\")\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    print(\"#############################################################\")\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init the cudnn and cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.optimizers import Adagrad, Adadelta, RMSprop, Adam, Adamax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test set from the disk. Let's visually see the structure of the dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directory_structure import Tree\n",
    "\n",
    "print(Tree(\"./dataset/test/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the test set from a given dir and normalize it. At the same time, we assign the batch size as 32 and target size as 64*64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    './dataset/test/',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model(s) from the disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a list of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models as a list.<br>\n",
    "<p style=\"color:#FF0000\";>Note, DO NOT perform this unless you have enough RAM in your computer!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trained = []\n",
    "\n",
    "# for file in os.scandir(\"./\"):\n",
    "#     if \"h5\" in file.name:\n",
    "#         model_trained.append({\n",
    "#             \"name\": file.name[:-2],\n",
    "#             \"model\": tf.keras.models.load_model(file.name),\n",
    "#         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Adagrad\"\n",
    "loaded_model_adagrad = tf.keras.models.load_model(model_name+\".h5\")\n",
    "print(\"Loaded {} model from disk\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know what binary value of each class is assigned, we can simply use \"train_set.class_indices\"\n",
    "<br>\n",
    "<br>\n",
    "Now we need to convert ImageDataGenerator to numpy representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# file_path = \"\"\n",
    "# test_img = image.load_img(file_path, target_size=(64,64))\n",
    "# test_img = image.img_to_array(test_img)\n",
    "# test_img = np.expand_dims(test_img, axis=0)\n",
    "\n",
    "# y_pred = loaded_model_adagrad.predict(test_set)\n",
    "\n",
    "# train_set.class_indices\n",
    "\n",
    "# if y_pred[0][0] == 1:\n",
    "#     print(\"Dog\")\n",
    "# else:\n",
    "#     print(\"Cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model_adagrad.predict(test_set)\n",
    "\n",
    "# the prediction result will be contious val, so we need to apply a method that's similar to sigmoid func\n",
    "y_pred = np.round_(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert \"flow_from_directory\" to numpy format. Ref: https://stackoverflow.com/questions/42284873/assign-imagedatagenerator-result-to-numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([test_set.next()[1] for i in range(test_set.__len__())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusionM(y_pred, title):\n",
    "    comf = confusion_matrix(y, y_pred)\n",
    "\n",
    "    # plot the confusion metrix\n",
    "    ax = sns.heatmap(comf, annot=True, cmap='Blues')\n",
    "\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['False','True'])\n",
    "    ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a detailed report about the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c377dff300a9ce94bc918435d1967ac8be21d56a2fbce5a27d1c5982784522b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow_gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
